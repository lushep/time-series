{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series - Trend & Seasonality\n",
    "\n",
    "Let's look at some data with some seasonal trends. The dataset we will use contains total monthly passenger traffic at Schiphol airport between 1999 and 2019 from [Statistics Netherlands (CBS)](https://opendata.cbs.nl/statline/#/CBS/en/dataset/37478ENG/table?dl=6F18). Each datapoint indicates the total number of passengers traveled via Schiphol in millions in each particular month.\n",
    "\n",
    "- [Visualising data and identifying trends](#trends)\n",
    "- [Separating trends, seasonal trends and residuals with Decomposition](#ets)\n",
    "- [Dealing with Seasonality](#seasonality)\n",
    "- [Feature engineering](#features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import dates\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data & divide by 1,000,000\n",
    "schiphol = pd.read_csv('data/schiphol_passengers.csv', index_col='date', parse_dates=True) / 1_000_000\n",
    "schiphol.index.freq = 'MS' #indicating that the time series has monthly frequency\n",
    "schiphol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='trends'></a>\n",
    "## Visualising and identifying trends\n",
    "\n",
    "Firstly, let's visualise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all data\n",
    "ax = schiphol.plot(figsize=(18,5))\n",
    "\n",
    "# Plot over one year - 2017\n",
    "ax = schiphol['2016-09-01':'2018-03-01'].plot(figsize=(18,6))\n",
    "ax.axvline('2017', color='grey', linestyle='--')\n",
    "ax.axvline('2018', color='grey', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When visualising time series data it is good to look out for:\n",
    "\n",
    "- **Trends**: Upward / horizontal / downward\n",
    "- **Seasonality**: Predictably repeating cycles - weekly/monthly/yearly etc\n",
    "- **Cyclic components**: Patterns with set repetition outside of seasonality\n",
    "- **Irregular components**: Patterns with no set repetition - for example trend breaks or random shocks\n",
    "- **Residuals**: The remaining part of the series that cannot be further explicitly modeled\n",
    "\n",
    "Is there a way to separate these?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ets'></a>\n",
    "## Error-Trend-Seasonality Decomposition\n",
    "\n",
    "We may want to separate the time series into the **trend**, the **seasonality** and the **error component** (ETS). ETS decomposition can be achieved by creating a generalized model that fits our data.\n",
    "\n",
    "`seasonal_decompose` from  `statsmodels` library can quickly provide a simple ETS decomposition:\n",
    "\n",
    "$$Y_t = T_t + S_t + e_t$$\n",
    "\n",
    "Each datapoint is split into a trend $Y_t$, seasonal $S_t$ and residual $e_t$ components. If the trend appears to be non-linear, `model='multiplicative'` option can be used, which implies the above decomposition with the terms multiplied rather than added up.\n",
    "\n",
    "Building such decompositions helps to inspect and analyze the general behavior of a time series. Note that we are not yet concerned with forecasting - our focus for now is understanding the current data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "Decomposition = seasonal_decompose(schiphol['total_passengers'], model = 'additive')  \n",
    "\n",
    "with plt.rc_context():\n",
    "    plt.rc(\"figure\", figsize=(16,10))\n",
    "    Decomposition.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly access the separated data points for trend `Decomposition.trend`, seasonality `Decomposition.seasonal` and residuals `Decomposition.resid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "schiphol.plot(ax = ax)\n",
    "Decomposition.trend.plot(ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another quick way to detect any recurrent patterns in the data is by using the *autocorrelation plot*. **Autocorrelation** allows us to look at the correlation between the current data and a lag of the data where lag can be defined. Often data to be correlated strongly when lag=1.\n",
    "\n",
    "Values close to -1 or 1 are considered to be strong correlated (negatively or positively). \n",
    "\n",
    "Used a lot in predicting stock prices, `.autocorr()` can tell us whether a stock price has momentum (positive correlation) or is mean reversing (negative correlation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the correlation with different lags\n",
    "lag = 1\n",
    "\n",
    "print(schiphol['total_passengers'].autocorr(lag))\n",
    "\n",
    "scat = (\n",
    "    schiphol\n",
    "    .assign(shift = schiphol['total_passengers'].shift(lag))\n",
    ")\n",
    "\n",
    "plt.scatter(scat['total_passengers'], scat['shift'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to just look at the autocorrelation for individual lags, let's use the `.plot_acf()` function from statsmodels to see for multiple lags side-by-side. Here we can see cyclical patterns in the autocorrelation plot which are likely signs of seasonal fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "fig, ax = plt.subplots(figsize = (16,4))\n",
    "plot_acf(schiphol['total_passengers'], lags = 48, ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ex-corr'></a>\n",
    "## <mark>Exercise - guess the Autocorrelation</mark>\n",
    "\n",
    "Can you correctly match the **graphs A, B, C, D** and **graphs 1, 2, 3, 4** to:\n",
    "\n",
    "- The [S&P 500](https://en.wikipedia.org/wiki/S%26P_500) total closing price daily\n",
    "- The monthly amount of processing of raw cow's milk into cheese products by dairy factories in the Netherlands\n",
    "- Hourly power consumption of a single household in Paris\n",
    "- Monthly Google trends for the word 'diet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply plotting the data:\n",
    "<img src='images/eg-plots.png'>\n",
    "\n",
    "Plotting the autocorrelation:\n",
    "<img src='images/eg-acf.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to play with the data (it's anonymised!) then head over to [this notebook](Exercise.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='seasonality'></a>\n",
    "## Dealing with Seasonality\n",
    "Seasonality obscures the actual signal, which complicates both understanding of the underlying processes and further forecasting. Understanding it gets us closer to what actually happens in the data â€• which also means easier forecasting.\n",
    "\n",
    "One of the simplest ways to identify the main pattern(s) taking place in the data is to fit a linear regression. We can learn about the general trend, (mostly) leaving the seasonality aside. We can evaluate the fit using the $R^2$ score - the closer to 1, the better the model captures the patterns in the data. Note though that this does not yet necessarily mean better forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy period variable X\n",
    "X = schiphol.assign(period_num=np.arange(len(schiphol.index))).drop('total_passengers', axis=1)\n",
    "y = schiphol['total_passengers'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "print(f\"R^2 is {round(lm.score(X, y),3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiphol.assign(pass_lin_pred=lm.predict(X)).plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple linear regression illustrates the overall passenger traffic growth over time, but (expectably) fails to take the 2009 drop into account. One way to correct this would be to introduce a dummy term for the data points after 2009:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_break = (\n",
    "    X\n",
    "    .assign(after2009 = [1 if el>pd.Timestamp('2009') else 0 for el in schiphol.index],\n",
    "            interaction = lambda df: df.period_num*df.after2009)\n",
    ")\n",
    "\n",
    "lm_break = LinearRegression().fit(X_break, y)\n",
    "print(f\"R^2 is {round(lm_break.score(X_break, y),3)}\")\n",
    "\n",
    "schiphol['pass_lin_b_pred'] = lm_break.predict(X_break)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schiphol[['total_passengers','pass_lin_b_pred']].plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be a much better fit. It also illustrates that even though passenger traffic dropped during the 2008-2009 Crisis, post-crisis growth appears to be more rapid than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='features'></a>\n",
    "## Feature Engineering\n",
    "\n",
    "We may want to do more than just identifying the trend though. Modeling the seasonality would allow us to understand and quantify the seasonal effects. And this means an ability to model not just the average behavior, but exact values during each season.\n",
    "\n",
    "A simple way to achieve this would be to add seasonal dummy terms to the baseline linear regression. In fact, *feature engineering* can be a very powerful tool in Time Series Analysis, allowing us to capture rather complex patterns with a few simple engineered variables added.\n",
    "\n",
    "In the code below, we use *ColumnTransformer* - a handy tool from scikit-learn to apply some transformation to one column (*'quarter'*) and keep the rest unchanged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying quarters and preprocessing them\n",
    "schiphol['quarter']=schiphol.index.quarter\n",
    "\n",
    "X_quarter = X.assign(quarter = schiphol.index.quarter)\n",
    "\n",
    "feature_transformer = ColumnTransformer(\n",
    "     [('numeric', 'passthrough', ['period_num']),\n",
    "      ('categorical', OneHotEncoder(sparse=False, drop='first'), ['quarter'])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further combine our preprocessing step with the model training using a Machine Learning pipeline from scikit-learn: a powerful way to keep both preprocessing and machine learning together in a single logical unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "model_quarter = Pipeline([\n",
    "    ('preprocess', feature_transformer),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "lm_quarter = model_quarter.fit(X_quarter, y)\n",
    "print(f\"R^2 is {round(lm_quarter.score(X_quarter, y),3)}\")\n",
    "\n",
    "schiphol['pass_lin_q_pred'] = lm_quarter.predict(X_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schiphol[['total_passengers','pass_lin_q_pred']].plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple model appears to reasonably capture the observed seasonality, even if it fails to acknowledge the drop after the 2008-2008 Financial Crisis. Actual seasonality seems more complex than just fixed quarterly jumps or drops, but this approach already illustrates the main patterns. \n",
    "\n",
    "Moreover, we can separate seasonality from the trend and the residuals to see what we're missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_season_effect = np.dot(lm_quarter['model'].coef_[1:],(0.25,0.25,0.25))\n",
    "\n",
    "simple_ets = (\n",
    "    schiphol\n",
    "    .loc[:,['total_passengers','pass_lin_q_pred']]\n",
    "    .rename(columns={\"total_passengers\": \"y_real\", \"pass_lin_q_pred\": \"y_hat\"})\n",
    "    .assign(residuals = lambda df: df['y_real']-df['y_hat'],\n",
    "            trend = lambda df: lm_quarter['model'].intercept_+lm_quarter['model'].coef_[0]*np.arange(len(df))+average_season_effect,\n",
    "            seasonal = lambda df: df['y_hat'] - df['trend'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ets[['y_real','y_hat','trend']].plot(figsize=(16,4))\n",
    "simple_ets[['seasonal']].plot(figsize=(16,2), c='m')\n",
    "simple_ets[['residuals']].plot(figsize=(16,2), c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case it is unclear from the residuals plot, we can also inspect the autocorrelation plot for the residuals to see if we have likely missed some important (seasonal) patterns with out model. In this case, based on the remaining autocorrelation in the residuals, our seasonality representation is clearly a bit too simplistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "plot_acf(simple_ets['residuals'], lags=48, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Monthly Dummies\n",
    "\n",
    "Instead of the quarterly dummies, let's add monthly dummies as well as post-2009 dummy. We can also add interaction and polinomial terms for all features\n",
    "\n",
    "Is it a better fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#identifying months and preprocessing them\n",
    "X_month = X_break.assign(month = X_break.index.month)\n",
    "\n",
    "feature_transformer = ColumnTransformer(\n",
    "     [('categorical', OneHotEncoder(sparse=False, drop='first'), ['month'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "#creating the model\n",
    "model_monthly = Pipeline([\n",
    "    ('preprocess', feature_transformer),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "#model fitting, predictions and plotting\n",
    "lm_poly = model_monthly.fit(X_month, y)\n",
    "print(f\"R^2 is {round(lm_poly.score(X_month, y),3)}\")\n",
    "\n",
    "schiphol['pass_poly_pred'] = lm_poly.predict(X_month)\n",
    "\n",
    "schiphol[['total_passengers','pass_poly_pred']].plot(figsize=(16,4));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
